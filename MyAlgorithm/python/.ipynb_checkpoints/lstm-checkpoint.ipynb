{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embeddings = 26\n",
    "embedding_dim = 3\n",
    "emb = nn.Embedding(num_embeddings, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3,4,5])\n",
    "x = emb(x).unsqueeze(1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = embedding_dim\n",
    "hidden_size = 6\n",
    "lstm = nn.LSTM( input_size ,  hidden_size, num_layers = 1, bidirectional = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_ii = lstm.weight_ih_l0[:hidden_size]\n",
    "W_if = lstm.weight_ih_l0[hidden_size:hidden_size*2]\n",
    "W_ig = lstm.weight_ih_l0[hidden_size*2:hidden_size*3]\n",
    "W_io = lstm.weight_ih_l0[hidden_size*3:]\n",
    "\n",
    "W_hi = lstm.weight_hh_l0[:hidden_size]\n",
    "W_hf = lstm.weight_hh_l0[hidden_size:hidden_size*2]\n",
    "W_hg = lstm.weight_hh_l0[hidden_size*2:hidden_size*3]\n",
    "W_ho = lstm.weight_hh_l0[hidden_size*3:]\n",
    "\n",
    "b_ii = lstm.bias_ih_l0[:hidden_size]\n",
    "b_if = lstm.bias_ih_l0[hidden_size:hidden_size*2]\n",
    "b_ig = lstm.bias_ih_l0[hidden_size*2:hidden_size*3]\n",
    "b_io = lstm.bias_ih_l0[hidden_size*3:]\n",
    "\n",
    "b_hi = lstm.bias_hh_l0[:hidden_size]\n",
    "b_hf = lstm.bias_hh_l0[hidden_size:hidden_size*2]\n",
    "b_hg = lstm.bias_hh_l0[hidden_size*2:hidden_size*3]\n",
    "b_ho = lstm.bias_hh_l0[hidden_size*3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 3.5591e-01, -1.6668e-01,  5.0164e-03,  7.6824e-02, -4.9371e-02,\n",
      "          2.8483e-04]], grad_fn=<TransposeBackward0>)\n",
      "tensor([[ 0.3421, -0.2757,  0.0861,  0.0047, -0.0971, -0.0536]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[ 0.2958, -0.1578,  0.1216,  0.0326, -0.0636,  0.0717]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[ 0.3395, -0.2268,  0.1474,  0.0125, -0.0498,  0.0195]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "tensor([[ 0.2856, -0.1752,  0.1543, -0.0018, -0.0790,  0.0782]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "\n",
      "tensor([[ 0.6083, -0.5396,  0.2967, -0.0040, -0.1860,  0.1845]],\n",
      "       grad_fn=<TransposeBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ht = torch.zeros(hidden_size, 1)\n",
    "ct = torch.zeros(hidden_size, 1)\n",
    "for i in range(len(x)):\n",
    "    xt = x[i]\n",
    "    it = torch.sigmoid(W_ii.mm(xt.transpose(0,1)) + b_ii.unsqueeze(1) +  W_hi.mm(ht) + b_hi.unsqueeze(1))\n",
    "    ft = torch.sigmoid(W_if.mm(xt.transpose(0,1)) + b_if.unsqueeze(1) +  W_hf.mm(ht) + b_hf.unsqueeze(1))\n",
    "    gt = torch.tanh(W_ig.mm(xt.transpose(0,1)) + b_ig.unsqueeze(1) +  W_hg.mm(ht) + b_hg.unsqueeze(1))\n",
    "    ot = torch.sigmoid(W_io.mm(xt.transpose(0,1)) + b_io.unsqueeze(1) +  W_ho.mm(ht) + b_ho.unsqueeze(1))\n",
    "    ct = ft * ct + it * gt\n",
    "    ht = ot * torch.tanh(ct)\n",
    "    print(ht.transpose(0,1))\n",
    "print()\n",
    "print(ct.transpose(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 3.5591e-01, -1.6668e-01,  5.0164e-03,  7.6824e-02, -4.9371e-02,\n",
       "            2.8483e-04]],\n",
       " \n",
       "         [[ 3.4206e-01, -2.7575e-01,  8.6137e-02,  4.6832e-03, -9.7088e-02,\n",
       "           -5.3595e-02]],\n",
       " \n",
       "         [[ 2.9580e-01, -1.5784e-01,  1.2163e-01,  3.2591e-02, -6.3551e-02,\n",
       "            7.1739e-02]],\n",
       " \n",
       "         [[ 3.3953e-01, -2.2675e-01,  1.4739e-01,  1.2475e-02, -4.9814e-02,\n",
       "            1.9518e-02]],\n",
       " \n",
       "         [[ 2.8555e-01, -1.7519e-01,  1.5431e-01, -1.8015e-03, -7.8964e-02,\n",
       "            7.8248e-02]]], grad_fn=<StackBackward>),\n",
       " (tensor([[[ 0.2856, -0.1752,  0.1543, -0.0018, -0.0790,  0.0782]]],\n",
       "         grad_fn=<StackBackward>),\n",
       "  tensor([[[ 0.6083, -0.5396,  0.2967, -0.0040, -0.1860,  0.1845]]],\n",
       "         grad_fn=<StackBackward>)))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0646],\n",
      "        [ 0.0126],\n",
      "        [-0.4932],\n",
      "        [ 0.0813],\n",
      "        [ 0.4289],\n",
      "        [ 0.7953]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a = nn.Parameter(torch.Tensor(6, 1))\n",
    "print(a)\n",
    "nn.init.xavier_normal_(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.W_ii = nn.Parameter(torch.Tensor(self.hidden_size, self.input_size))\n",
    "        self.W_if = nn.Parameter(torch.Tensor(self.hidden_size, self.input_size))\n",
    "        self.W_ig = nn.Parameter(torch.Tensor(self.hidden_size, self.input_size))\n",
    "        self.W_io = nn.Parameter(torch.Tensor(self.hidden_size, self.input_size))\n",
    "\n",
    "        self.W_hi = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
    "        self.W_hf = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
    "        self.W_hg = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
    "        self.W_ho = nn.Parameter(torch.Tensor(self.hidden_size, self.hidden_size))\n",
    "\n",
    "        self.b_ii = nn.Parameter(torch.Tensor(self.hidden_size, 1))\n",
    "        self.b_if = nn.Parameter(torch.Tensor(self.hidden_size, 1))\n",
    "        self.b_ig = nn.Parameter(torch.Tensor(self.hidden_size, 1))\n",
    "        self.b_io = nn.Parameter(torch.Tensor(self.hidden_size, 1))\n",
    "\n",
    "        self.b_hi = nn.Parameter(torch.Tensor(self.hidden_size, 1))\n",
    "        self.b_hf = nn.Parameter(torch.Tensor(self.hidden_size, 1))\n",
    "        self.b_hg = nn.Parameter(torch.Tensor(self.hidden_size, 1))\n",
    "        self.b_ho = nn.Parameter(torch.Tensor(self.hidden_size, 1))\n",
    "        \n",
    "        self.initWeight()\n",
    "    def initWeight(self):\n",
    "        nn.init.xavier_normal_(self.W_ii)\n",
    "        nn.init.xavier_normal_(self.W_if)\n",
    "        nn.init.xavier_normal_(self.W_ig)\n",
    "        nn.init.xavier_normal_(self.W_io)\n",
    "        nn.init.xavier_normal_(self.W_hi)\n",
    "        nn.init.xavier_normal_(self.W_hf)\n",
    "        nn.init.xavier_normal_(self.W_hg)\n",
    "        nn.init.xavier_normal_(self.W_ho)\n",
    "        nn.init.xavier_normal_(self.b_ii)\n",
    "        nn.init.xavier_normal_(self.b_if)\n",
    "        nn.init.xavier_normal_(self.b_ig)\n",
    "        nn.init.xavier_normal_(self.b_io)\n",
    "        nn.init.xavier_normal_(self.b_hi)\n",
    "        nn.init.xavier_normal_(self.b_hf)\n",
    "        nn.init.xavier_normal_(self.b_hg)\n",
    "        nn.init.xavier_normal_(self.b_ho)\n",
    "    # todo: input hidden\n",
    "    def forward(self, x):\n",
    "        # x [lenSeq, batchSize, nFeatures]\n",
    "        \n",
    "        res = torch.Tensor(x.shape[0], x.shape[1], hidden_size)\n",
    "        ht = torch.zeros( self.hidden_size, 1)\n",
    "        ct = torch.zeros( self.hidden_size, 1)\n",
    "        for i in range(len(x)):\n",
    "            xt = x[i]\n",
    "            it = torch.sigmoid(self.W_ii.mm(xt.transpose(0,1)) + self.b_ii +  self.W_hi.mm(ht) + self.b_hi)\n",
    "            ft = torch.sigmoid(self.W_if.mm(xt.transpose(0,1)) + self.b_if +  self.W_hf.mm(ht) + self.b_hf)\n",
    "            gt = torch.tanh(self.W_ig.mm(xt.transpose(0,1)) + self.b_ig +  self.W_hg.mm(ht) + self.b_hg)\n",
    "            ot = torch.sigmoid(self.W_io.mm(xt.transpose(0,1)) + self.b_io +  self.W_ho.mm(ht) + self.b_ho)\n",
    "            ct = ft * ct + it * gt\n",
    "            ht = ot * torch.tanh(ct)\n",
    "            res[i, 0] = ht.squeeze(1)\n",
    "        return res, (ht.transpose(0,1).unsqueeze(0), ct.transpose(0,1).unsqueeze(0))\n",
    "mlstm = MyLSTM(input_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1281,  0.2257,  0.3533,  0.3819,  0.1263,  0.0016]],\n",
       " \n",
       "         [[-0.0973,  0.1956,  0.2991,  0.3740,  0.1990, -0.1664]],\n",
       " \n",
       "         [[-0.0779,  0.3853,  0.3049, -0.0108,  0.1184, -0.1146]],\n",
       " \n",
       "         [[-0.0171,  0.2958,  0.3935, -0.1407,  0.1658, -0.0881]],\n",
       " \n",
       "         [[-0.1013,  0.4276,  0.3682, -0.0877,  0.1327, -0.0884]]],\n",
       "        grad_fn=<CopySlices>),\n",
       " (tensor([[[-0.1013,  0.4276,  0.3682, -0.0877,  0.1327, -0.0884]]],\n",
       "         grad_fn=<UnsqueezeBackward0>),\n",
       "  tensor([[[-0.2218,  0.7667,  0.6361, -0.2010,  0.1967, -0.1630]]],\n",
       "         grad_fn=<UnsqueezeBackward0>)))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlstm.initWeight()\n",
    "mlstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 3.5591e-01, -1.6668e-01,  5.0164e-03,  7.6824e-02, -4.9371e-02,\n",
       "            2.8483e-04]],\n",
       " \n",
       "         [[ 3.4206e-01, -2.7575e-01,  8.6137e-02,  4.6832e-03, -9.7088e-02,\n",
       "           -5.3595e-02]],\n",
       " \n",
       "         [[ 2.9580e-01, -1.5784e-01,  1.2163e-01,  3.2591e-02, -6.3551e-02,\n",
       "            7.1739e-02]],\n",
       " \n",
       "         [[ 3.3953e-01, -2.2675e-01,  1.4739e-01,  1.2475e-02, -4.9814e-02,\n",
       "            1.9518e-02]],\n",
       " \n",
       "         [[ 2.8555e-01, -1.7519e-01,  1.5431e-01, -1.8015e-03, -7.8964e-02,\n",
       "            7.8248e-02]]], grad_fn=<StackBackward>),\n",
       " (tensor([[[ 0.2856, -0.1752,  0.1543, -0.0018, -0.0790,  0.0782]]],\n",
       "         grad_fn=<StackBackward>),\n",
       "  tensor([[[ 0.6083, -0.5396,  0.2967, -0.0040, -0.1860,  0.1845]]],\n",
       "         grad_fn=<StackBackward>)))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
